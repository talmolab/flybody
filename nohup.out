2024-07-22 18:15:30,549	WARNING services.py:2010 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67088384 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.
2024-07-22 18:15:30,664	INFO worker.py:1779 -- Started a local Ray instance. View the dashboard at [1m[32m10.244.9.103:8265 [39m[22m
/root/anaconda3/envs/flybody/lib/python3.10/site-packages/reverb/platform/default/ensure_tf_install.py:53: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  if (distutils.version.LooseVersion(version) <
/root/anaconda3/envs/flybody/lib/python3.10/site-packages/reverb/platform/default/ensure_tf_install.py:54: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  distutils.version.LooseVersion(required_tensorflow_version)):
/root/talmolab-smb/kaiwen/flybody/flybody/agents/learning_dmpo.py:343: DeprecationWarning: invalid escape sequence '\d'
  current_counter = re.findall('[\d]+$', path)[0]
2024-07-22 18:15:37.770388: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
[36m(ReplayServer pid=500309)[0m 2024-07-22 18:15:40.573952: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
[36m(ReplayServer pid=500309)[0m [reverb/cc/platform/tfrecord_checkpointer.cc:150]  Initializing TFRecordCheckpointer in /tmp/tmpod8jggti.
[36m(ReplayServer pid=500309)[0m [reverb/cc/platform/tfrecord_checkpointer.cc:386] Loading latest checkpoint from /tmp/tmpod8jggti
[36m(ReplayServer pid=500309)[0m [reverb/cc/platform/default/server.cc:71] Started replay server on port 45729
[36m(Learner pid=500589)[0m 2024-07-22 18:15:43.449534: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
[36m(Learner pid=500589)[0m WARNING:tensorflow:From /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.
[36m(Learner pid=500589)[0m Instructions for updating:
[36m(Learner pid=500589)[0m Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
[36m(Learner pid=500589)[0m 2024-07-22 18:15:44.423637: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
[36m(EnvironmentLoop pid=500949)[0m 2024-07-22 18:15:48.870131: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
[36m(EnvironmentLoop pid=500951)[0m 2024-07-22 18:15:49.178436: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
[36m(EnvironmentLoop pid=502330)[0m 2024-07-22 18:15:54.401194: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected[32m [repeated 18x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(EnvironmentLoop pid=500951)[0m WARNING:tensorflow:From /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.
[36m(EnvironmentLoop pid=500951)[0m Instructions for updating:
[36m(EnvironmentLoop pid=500951)[0m Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
[36m(EnvironmentLoop pid=500951)[0m WARNING:tensorflow:From /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.
[36m(EnvironmentLoop pid=500951)[0m Instructions for updating:
[36m(EnvironmentLoop pid=500951)[0m Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.
[36m(EnvironmentLoop pid=500951)[0m 2024-07-22 18:15:57.637713: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
[36m(EnvironmentLoop pid=506123)[0m 2024-07-22 18:15:59.878221: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected[32m [repeated 22x across cluster][0m
[36m(EnvironmentLoop pid=501012)[0m WARNING:tensorflow:From /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.[32m [repeated 6x across cluster][0m
[36m(EnvironmentLoop pid=501012)[0m Instructions for updating:[32m [repeated 6x across cluster][0m
[36m(EnvironmentLoop pid=501012)[0m Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.[32m [repeated 6x across cluster][0m
[36m(EnvironmentLoop pid=501012)[0m 2024-07-22 18:16:00.438222: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.[32m [repeated 3x across cluster][0m
[36m(EnvironmentLoop pid=509813)[0m 2024-07-22 18:16:04.022917: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected[32m [repeated 19x across cluster][0m
[36m(EnvironmentLoop pid=504031)[0m WARNING:tensorflow:From /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.[32m [repeated 32x across cluster][0m
[36m(EnvironmentLoop pid=504031)[0m Instructions for updating:[32m [repeated 32x across cluster][0m
[36m(EnvironmentLoop pid=504031)[0m Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.[32m [repeated 32x across cluster][0m
[36m(EnvironmentLoop pid=504031)[0m 2024-07-22 18:16:10.457460: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.[32m [repeated 16x across cluster][0m
[36m(EnvironmentLoop pid=507565)[0m WARNING:tensorflow:From /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.[32m [repeated 80x across cluster][0m
[36m(EnvironmentLoop pid=507565)[0m Instructions for updating:[32m [repeated 80x across cluster][0m
[36m(EnvironmentLoop pid=507565)[0m Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.[32m [repeated 80x across cluster][0m
[36m(EnvironmentLoop pid=507565)[0m 2024-07-22 18:16:15.528696: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.[32m [repeated 39x across cluster][0m
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_probability.python.distributions.independent.Independent_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tfp.distributions.Normal_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(EnvironmentLoop pid=507752)[0m WARNING:tensorflow:From /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling _Independent.__init__ (from tensorflow_probability.python.distributions.independent) with reinterpreted_batch_ndims=None is deprecated and will be removed after 2022-03-01.[32m [repeated 2x across cluster][0m
[36m(EnvironmentLoop pid=507752)[0m Instructions for updating:[32m [repeated 2x across cluster][0m
[36m(EnvironmentLoop pid=507752)[0m Please pass an integer value for `reinterpreted_batch_ndims`. The current behavior corresponds to `reinterpreted_batch_ndims=tf.size(distribution.batch_shape_tensor()) - 1`.[32m [repeated 2x across cluster][0m
[36m(EnvironmentLoop pid=509131)[0m 2024-07-22 18:16:15.448873: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.[32m [repeated 2x across cluster][0m
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_probability.python.distributions.independent.Independent_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tfp.distributions.Normal_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_probability.python.distributions.independent.Independent_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tfp.distributions.Normal_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[33m(raylet)[0m [2024-07-22 19:27:30,742 E 495307 495307] (raylet) node_manager.cc:3064: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c2549f97b656eb847bf9faf6ae72f2f594da40397b014dc2452b4bed, IP: 10.244.9.103) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.244.9.103`
[33m(raylet)[0m 
[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[33m(raylet)[0m 
[33m(raylet)[0m [2024-07-22 19:28:30,743 E 495307 495307] (raylet) node_manager.cc:3064: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c2549f97b656eb847bf9faf6ae72f2f594da40397b014dc2452b4bed, IP: 10.244.9.103) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.244.9.103`
[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[33m(raylet)[0m [2024-07-22 19:30:30,746 E 495307 495307] (raylet) node_manager.cc:3064: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c2549f97b656eb847bf9faf6ae72f2f594da40397b014dc2452b4bed, IP: 10.244.9.103) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.244.9.103`
[33m(raylet)[0m 
[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[33m(raylet)[0m 
[33m(raylet)[0m [2024-07-22 19:31:30,748 E 495307 495307] (raylet) node_manager.cc:3064: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c2549f97b656eb847bf9faf6ae72f2f594da40397b014dc2452b4bed, IP: 10.244.9.103) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.244.9.103`
[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[33m(raylet)[0m [2024-07-22 19:33:30,752 E 495307 495307] (raylet) node_manager.cc:3064: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c2549f97b656eb847bf9faf6ae72f2f594da40397b014dc2452b4bed, IP: 10.244.9.103) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.244.9.103`
[33m(raylet)[0m 
[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[33m(raylet)[0m 
[33m(raylet)[0m [2024-07-22 19:35:30,757 E 495307 495307] (raylet) node_manager.cc:3064: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c2549f97b656eb847bf9faf6ae72f2f594da40397b014dc2452b4bed, IP: 10.244.9.103) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.244.9.103`
[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[33m(raylet)[0m [2024-07-22 19:37:30,761 E 495307 495307] (raylet) node_manager.cc:3064: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c2549f97b656eb847bf9faf6ae72f2f594da40397b014dc2452b4bed, IP: 10.244.9.103) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.244.9.103`
[33m(raylet)[0m 
[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[33m(raylet)[0m 
[33m(raylet)[0m [2024-07-22 19:39:30,765 E 495307 495307] (raylet) node_manager.cc:3064: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c2549f97b656eb847bf9faf6ae72f2f594da40397b014dc2452b4bed, IP: 10.244.9.103) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.244.9.103`
[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[33m(raylet)[0m [2024-07-22 19:42:30,771 E 495307 495307] (raylet) node_manager.cc:3064: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c2549f97b656eb847bf9faf6ae72f2f594da40397b014dc2452b4bed, IP: 10.244.9.103) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.244.9.103`
[33m(raylet)[0m 
[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[33m(raylet)[0m 
[33m(raylet)[0m [2024-07-22 19:44:30,775 E 495307 495307] (raylet) node_manager.cc:3064: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c2549f97b656eb847bf9faf6ae72f2f594da40397b014dc2452b4bed, IP: 10.244.9.103) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.244.9.103`
[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_probability.python.distributions.independent.Independent_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tfp.distributions.Normal_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[33m(raylet)[0m [2024-07-22 19:47:30,781 E 495307 495307] (raylet) node_manager.cc:3064: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c2549f97b656eb847bf9faf6ae72f2f594da40397b014dc2452b4bed, IP: 10.244.9.103) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.244.9.103`
[33m(raylet)[0m 
[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[33m(raylet)[0m 
[33m(raylet)[0m [2024-07-22 19:49:30,786 E 495307 495307] (raylet) node_manager.cc:3064: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c2549f97b656eb847bf9faf6ae72f2f594da40397b014dc2452b4bed, IP: 10.244.9.103) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.244.9.103`
[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[33m(raylet)[0m [2024-07-22 19:51:30,791 E 495307 495307] (raylet) node_manager.cc:3064: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c2549f97b656eb847bf9faf6ae72f2f594da40397b014dc2452b4bed, IP: 10.244.9.103) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.244.9.103`
[33m(raylet)[0m 
[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[33m(raylet)[0m 
[33m(raylet)[0m [2024-07-22 19:53:30,795 E 495307 495307] (raylet) node_manager.cc:3064: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c2549f97b656eb847bf9faf6ae72f2f594da40397b014dc2452b4bed, IP: 10.244.9.103) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.244.9.103`
[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[33m(raylet)[0m [2024-07-22 19:56:30,802 E 495307 495307] (raylet) node_manager.cc:3064: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c2549f97b656eb847bf9faf6ae72f2f594da40397b014dc2452b4bed, IP: 10.244.9.103) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.244.9.103`
[33m(raylet)[0m 
[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[33m(raylet)[0m 
[33m(raylet)[0m [2024-07-22 19:59:30,808 E 495307 495307] (raylet) node_manager.cc:3064: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c2549f97b656eb847bf9faf6ae72f2f594da40397b014dc2452b4bed, IP: 10.244.9.103) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.244.9.103`
[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[33m(raylet)[0m [2024-07-22 20:04:30,817 E 495307 495307] (raylet) node_manager.cc:3064: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c2549f97b656eb847bf9faf6ae72f2f594da40397b014dc2452b4bed, IP: 10.244.9.103) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.244.9.103`
[33m(raylet)[0m 
[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[36m(Learner pid=500589)[0m WARNING:tensorflow:5 out of the last 5 calls to <function MultiDeviceSaver.save.<locals>.tf_function_save at 0x7f1f0436ae60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
[36m(Learner pid=500589)[0m WARNING:tensorflow:5 out of the last 5 calls to <function MultiDeviceSaver.save.<locals>.tf_function_save at 0x7f1f0436ae60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_probability.python.distributions.independent.Independent_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tfp.distributions.Normal_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m WARNING:tensorflow:6 out of the last 6 calls to <function MultiDeviceSaver.save.<locals>.tf_function_save at 0x7f1f0436b0a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
[36m(Learner pid=500589)[0m WARNING:tensorflow:6 out of the last 6 calls to <function MultiDeviceSaver.save.<locals>.tf_function_save at 0x7f1f0436b0a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_probability.python.distributions.independent.Independent_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tfp.distributions.Normal_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[33m(raylet)[0m [2024-07-22 20:56:30,930 E 495307 495307] (raylet) node_manager.cc:3064: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c2549f97b656eb847bf9faf6ae72f2f594da40397b014dc2452b4bed, IP: 10.244.9.103) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.244.9.103`
[33m(raylet)[0m 
[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_probability.python.distributions.independent.Independent_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tfp.distributions.Normal_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_probability.python.distributions.independent.Independent_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tfp.distributions.Normal_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[33m(raylet)[0m [2024-07-22 22:15:31,103 E 495307 495307] (raylet) node_manager.cc:3064: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c2549f97b656eb847bf9faf6ae72f2f594da40397b014dc2452b4bed, IP: 10.244.9.103) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.244.9.103`
[33m(raylet)[0m 
[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_probability.python.distributions.independent.Independent_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tfp.distributions.Normal_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_probability.python.distributions.independent.Independent_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tfp.distributions.Normal_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[33m(raylet)[0m [2024-07-22 23:05:31,218 E 495307 495307] (raylet) node_manager.cc:3064: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c2549f97b656eb847bf9faf6ae72f2f594da40397b014dc2452b4bed, IP: 10.244.9.103) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.244.9.103`
[33m(raylet)[0m 
[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_probability.python.distributions.independent.Independent_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tfp.distributions.Normal_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_probability.python.distributions.independent.Independent_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tfp.distributions.Normal_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_probability.python.distributions.independent.Independent_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tfp.distributions.Normal_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_probability.python.distributions.independent.Independent_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tfp.distributions.Normal_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_probability.python.distributions.independent.Independent_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tfp.distributions.Normal_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_probability.python.distributions.independent.Independent_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tfp.distributions.Normal_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_probability.python.distributions.independent.Independent_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tfp.distributions.Normal_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_probability.python.distributions.independent.Independent_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tfp.distributions.Normal_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[33m(raylet)[0m [2024-07-23 03:00:39,461 E 495307 495307] (raylet) node_manager.cc:3064: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: c2549f97b656eb847bf9faf6ae72f2f594da40397b014dc2452b4bed, IP: 10.244.9.103) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.244.9.103`
[33m(raylet)[0m 
[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_probability.python.distributions.independent.Independent_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tfp.distributions.Normal_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_probability.python.distributions.independent.Independent_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tfp.distributions.Normal_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tensorflow_probability.python.distributions.independent.Independent_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
[36m(Learner pid=500589)[0m /root/anaconda3/envs/flybody/lib/python3.10/site-packages/tensorflow/python/saved_model/nested_structure_coder.py:522: UserWarning: Encoding a StructuredValue with type tfp.distributions.Normal_ACTTypeSpec; loading this StructuredValue will require that this type be imported and registered.
[36m(Learner pid=500589)[0m   warnings.warn("Encoding a StructuredValue with type %s; loading this "
